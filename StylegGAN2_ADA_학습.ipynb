{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StylegGAN2-ADA 학습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piat0046/PractiseProject/blob/master/StylegGAN2_ADA_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fN-d1-N9s0"
      },
      "source": [
        "# StyleGAN2-ADA 모델 학습하기\n",
        "\n",
        "이 노트북은 다음 노트북을 합쳐서 만들고 한글 설명을 추가했습니다.\n",
        "\n",
        "- https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb\n",
        "- https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFB64iL9BzBd"
      },
      "source": [
        "StyleGAN2-ADA 모델은 텐서플로우 1 버전에서만 작동합니다. 아래 셀을 실행해서 1 버전을 사용할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "F_uBNAqH4yWR",
        "outputId": "e4971988-90aa-4d95-f04c-7ea3786bf12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 8.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbyUpDO4OLiU",
        "outputId": "76f5ea94-6ce6-47e2-990e-201e80e0ef4f"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91s4Bdk2CAJi"
      },
      "source": [
        "현재 구글에서 어떤 GPU를 할당받았는지 알아봅니다. 노트북 위의 메뉴에서 Runtime > Change runtime type 으로 가서 GPU가 선택되었는지 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBLUTr7OVoB",
        "outputId": "bc2985e4-6508-466e-fe2c-9129a8bca878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar 19 11:24:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhGEeUh8CEMc"
      },
      "source": [
        "내 구글 계정의 드라이브를 이 노트북과 연동시킵니다. 앞으로는 구글 드라이브의 파일을 노트북에서 가져다쓰거나, 노트북에서 생성된 파일들을 내 드라이브로 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F46YSLmVOWWa",
        "outputId": "56cbdc35-9b52-4be3-d243-af07cb0cdd73"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1jG7Cx1RWKY"
      },
      "source": [
        "## Clone StyleGAN2-ADA Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDEl_QC6CbDr"
      },
      "source": [
        "StyleGAN2-ADA 관련된 코드를 노트북으로 불러와서 다운로드받습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVtHBVKbOmKl",
        "outputId": "cafefc38-e603-4f69-e920-02479cd05956"
      },
      "source": [
        "# Download the code\n",
        "%cd /content/\n",
        "!git clone https://github.com/dvschultz/stylegan2-ada.git\n",
        "!mkdir downloads\n",
        "!mkdir datasets"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Total 364 (delta 0), reused 0 (delta 0), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (364/364), 56.17 MiB | 34.06 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffxQiIkQRTGO"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa5ILnoJXNXq"
      },
      "source": [
        "이번 노트북에서 학습에 사용할 데이터는 포켓몬 이미지 데이터입니다. 다음 링크에서 다운로드받을 수 있습니다:\n",
        "\n",
        "https://www.kaggle.com/kvpratama/pokemon-images-dataset\n",
        "\n",
        "다운로드받은 파일은 각자의 구글 드라이브 폴더에 미리 업로드시켜주세요. 업로드한 후에는, 이 노트북에서 데이터를 불러와서 학습에 사용할 수 있습니다. 여기서는 포켓몬 데이터셋 (256x256)을 사용하지만, 다른 데이터셋으로 학습도 가능합니다.\n",
        "\n",
        "데이터셋의 이름을 zip파일 이름으로 바꿔주세요:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w637CVdoO3du"
      },
      "source": [
        "dataset_name = \"download1\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NKBXJsUC1Cc"
      },
      "source": [
        "노트북으로 데이터셋 압축파일을 불러와서 압축을 풉니다. 왼쪽 Files에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tdy-VknQbkW",
        "outputId": "e2881dcd-4115-4e9e-ade0-ccdcad461e65"
      },
      "source": [
        "import zipfile\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "dataset = dataset_name + \".zip\"\n",
        "local_path = \"/content/man/\"\n",
        "file_name = path + dataset\n",
        "with zipfile.ZipFile(file_name, 'r') as zip:\n",
        "   #zip.printdir()\n",
        "   print('Extracting all the files now...') \n",
        "   zip.extractall(local_path) \n",
        "   print('Done!')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "IgEC_M8qXPUG",
        "outputId": "6099b5a0-395b-42e3-f849-521f61b504fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aydao_flesh_digressions.py  Dockerfile\t  LICENSE.txt\tstyle_mixing.py\n",
            "blend_models.py\t\t    docs\t  metrics\ttonni\n",
            "calc_metrics.py\t\t    ffhq_dataset  notebooks\ttraining\n",
            "dataset_tool.py\t\t    generate.py   projector.py\ttrain.py\n",
            "dnnlib\t\t\t    grid_vid.py   README.md\tutils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxtOLRCvDULH"
      },
      "source": [
        "불러온 이미지 데이터셋 jpg 파일들을 텐서플로에서 사용할 수 있는 데이터셋 포맷(tfrecords)으로 바꿔줍니다. 이 변환과정이 데이터셋의 크기에 따라 굉장히 오래 걸릴 수 있습니다. 이미지 파일들이 저장되어있는 경로를 잘 설정해줘야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlS7sB4xQtmC",
        "outputId": "7397a3c1-11be-4430-9ae8-5740dc50b83f"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "#update this to the path to your image folder\n",
        "dataset_path = \"/content/stylegan2-ada/tonni/aligned\"\n",
        "\n",
        "#you don't need to edit anything here\n",
        "%cd /content/stylegan2-ada\n",
        "!python dataset_tool.py create_from_images /content/datasets/{dataset_name} {dataset_path}"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/stylegan2-ada\n",
            "Loading images from \"/content/stylegan2-ada/tonni/aligned\"\n",
            "Creating dataset \"/content/datasets/download1\"\n",
            "dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 1550 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset_tool.py -help"
      ],
      "metadata": {
        "id": "YXk5hCPO9WX3",
        "outputId": "d4f7b750-e22e-45ac-9057-ee28f401587e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: dataset_tool.py [-h]\n",
            "                       {info,display,extract,compare,create_mnist,create_mnistrgb,create_cifar10,create_cifar100,create_svhn,create_lsun,create_lsun_wide,create_celeba,create_from_images,create_from_images_raw,create_from_image_folders,create_from_image_folders_raw,create_from_images_with_labels,create_from_hdf5,convert_to_hdf5,hdf5_from_images,unpack,pack,extract_brecahad_crops}\n",
            "                       ...\n",
            "dataset_tool.py: error: argument -h/--help: ignored explicit argument 'elp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhe_tggRPnq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrikBYS-VOnO"
      },
      "source": [
        "학습할 때 우리가 조절할 수 있는 다양한 패러미터들이 있습니다. 다음 셀을 실행하면 도움말을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPPicfQXQ_PZ",
        "outputId": "45fae2a1-e590-454c-ec7f-3ecd49efa90d"
      },
      "source": [
        "%cd /content/stylegan2-ada\n",
        "!python train.py --help"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n",
            "usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n",
            "                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n",
            "                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n",
            "                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n",
            "                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n",
            "                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n",
            "                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n",
            "                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n",
            "                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n",
            "                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n",
            "\n",
            "Train a GAN using the techniques described in the paper\n",
            "\"Training Generative Adversarial Networks with Limited Data\".\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "general options:\n",
            "  --outdir DIR          Where to save the results (required)\n",
            "  --gpus INT            Number of GPUs to use (default: 1 gpu)\n",
            "  --snap INT            Snapshot interval (default: 50 ticks)\n",
            "  --seed INT            Random seed (default: 1000)\n",
            "  -n, --dry-run         Print training options and exit\n",
            "\n",
            "training dataset:\n",
            "  --data PATH           Training dataset path (required)\n",
            "  --res INT             Dataset resolution (default: highest available)\n",
            "  --mirror BOOL         Augment dataset with x-flips (default: false)\n",
            "  --mirrory BOOL        Augment dataset with y-flips (default: false)\n",
            "  --use-raw BOOL        Use raw image dataset, i.e. created from\n",
            "                        create_from_images_raw (default: False)\n",
            "\n",
            "metrics:\n",
            "  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n",
            "  --metricdata PATH     Dataset to evaluate metrics against (optional)\n",
            "\n",
            "base config:\n",
            "  --cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}\n",
            "                        Base config (default: auto)\n",
            "  --lrate FLOAT         Override learning rate\n",
            "  --ttur BOOL           Use Two Time-Scale Update Rule (double learning rate\n",
            "                        for discriminator) (default: false)\n",
            "  --gamma FLOAT         Override R1 gamma\n",
            "  --nkimg INT           Override starting count\n",
            "  --kimg INT            Override training duration\n",
            "  --topk FLOAT          utilize top-k training\n",
            "\n",
            "discriminator augmentation:\n",
            "  --aug {noaug,ada,fixed,adarv}\n",
            "                        Augmentation mode (default: ada)\n",
            "  --p FLOAT             Specify augmentation probability for --aug=fixed\n",
            "  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n",
            "  --initstrength INITSTRENGTH\n",
            "                        Override ADA strength at start\n",
            "  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n",
            "                        Augmentation pipeline (default: bgc)\n",
            "\n",
            "comparison methods:\n",
            "  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n",
            "                        Comparison method (default: nocmethod)\n",
            "  --dcap FLOAT          Multiplier for discriminator capacity\n",
            "\n",
            "transfer learning:\n",
            "  --resume RESUME       Resume from network pickle (default: noresume)\n",
            "  --freezed INT         Freeze-D (default: 0 discriminator layers)\n",
            "\n",
            "examples:\n",
            "\n",
            "  # Train custom dataset using 1 GPU.\n",
            "  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n",
            "\n",
            "  # Train class-conditional CIFAR-10 using 2 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n",
            "      --cfg=cifar\n",
            "\n",
            "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n",
            "  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n",
            "      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n",
            "\n",
            "  # Reproduce original StyleGAN2 config F.\n",
            "  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n",
            "      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n",
            "\n",
            "available base configs (--cfg):\n",
            "  auto           Automatically select reasonable defaults based on resolution\n",
            "                 and GPU count. Good starting point for new datasets.\n",
            "  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n",
            "  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n",
            "  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n",
            "  paper1024      Reproduce results for MetFaces at 1024x1024.\n",
            "  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n",
            "  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n",
            "\n",
            "transfer learning source networks (--resume):\n",
            "  ffhq256        FFHQ trained at 256x256 resolution.\n",
            "  ffhq512        FFHQ trained at 512x512 resolution.\n",
            "  ffhq1024       FFHQ trained at 1024x1024 resolution.\n",
            "  celebahq256    CelebA-HQ trained at 256x256 resolution.\n",
            "  lsundog256     LSUN Dog trained at 256x256 resolution.\n",
            "  afhqcat512     AFHQ Cat trained at 512x512 resolution.\n",
            "  afhqdog512     AFHQ Dog trained at 512x512 resolution.\n",
            "  afhqwild512    AFHQ Wild trained at 512x512 resolution.\n",
            "  brecahad512    BreCaHAD trained at 512x512 resolution.\n",
            "  cifar10        CIFAR10 trained at 32x32 resolution.\n",
            "  metfaces512    MetFaces trained at 512x512 resolution.\n",
            "  <path or URL>  Custom network pickle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlt3UUwVWmg"
      },
      "source": [
        "아래 셀을 실행하면 학습이 시작됩니다. **학습이 진행되는 동안에는, 이 노트북 창을 열어두어야 합니다.** 노트북 창을 닫거나 인터넷 연결이 끊기면, 콜랩 노트북의 실행이 중단됩니다. 또, 너무 오랜시간동안 실행되고 있는 노트북은 구글에서 자동으로 차단합니다. 연결이 끊긴 경우에는 이 노트북을 처음 셀부터 다시 실행해야합니다. 연결이 끊긴 후에 이어서 학습을 하고 싶은 경우에는 `resume_from` 경로를 최근의 `pkl` 파일 경로로 바꿔주세요.\n",
        "\n",
        "학습이 진행되는 동안 구글 드라이브 폴더를 확인해보세요. 중간 과정의 이미지 결과물과 모델을 자동으로 저장합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "t5gkUwO5pNmk",
        "outputId": "48cd6a59-177c-4c01-9413-bad5eb719b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo53TCYVRKW0",
        "outputId": "c68f60db-dc58-491f-c499-beb246f69c72"
      },
      "source": [
        "# output directory\n",
        "output_dir = '/content/drive/MyDrive/Colab\\ Notebooks/results/' + dataset_name + \"/\"\n",
        "\n",
        "# config\n",
        "config = \"auto\"\n",
        "\n",
        "# gamma\n",
        "gamma = 1\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 2\n",
        "\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#\n",
        "# this is the most important cell to update\n",
        "#\n",
        "# running it for the first time? set it to ffhq(+resolution)\n",
        "# resuming? get the path to your latest .pkl file and use that\n",
        "resume_from = \"ffhq512\"\n",
        "\n",
        "# make sure there is no space in the resume path. if there is any, use a backslash character to escape\n",
        "# resume_from = '/content/drive/MyDrive/Colab\\ Notebooks/results/pokemon-256/00001-pokemon-256-mirror-auto1-gamma1-resumecustom/network-snapshot-000036.pkl'\n",
        "\n",
        "# seed\n",
        "\n",
        "#don't edit this unless you know what you're doing :)\n",
        "!python train.py --outdir={output_dir} \\\n",
        "                 --cfg={config} \\\n",
        "                 --snap={snapshot_count} \\\n",
        "                 --data=/content/stylegan2-ada/download1 \\\n",
        "                 --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "                 --gamma={gamma} \\\n",
        "                 --metrics={metric_list} \\\n",
        "                 --resume={resume_from} \\\n",
        "                 --seed=900"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 4294967296 bytes == 0x55702c596000 @  0x7fd08865f001 0x7fd08586254f 0x7fd0858b2b58 0x7fd0858b6b17 0x7fd085955203 0x557023af6424 0x557023af6120 0x557023b6ab80 0x557023b6566e 0x557023af836c 0x557023b397b9 0x557023b366d4 0x557023af6c29 0x557023b6ae61 0x557023b6502f 0x557023a36e2b 0x557023b67633 0x557023b6502f 0x557023a36e2b 0x557023b67633 0x557023b6566e 0x557023a36e2b 0x557023b67633 0x557023af79da 0x557023b65eae 0x557023b6502f 0x557023b64d43 0x557023c2f302 0x557023c2f67d 0x557023c2f526 0x557023c071d3\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55712c596000 @  0x7fd08865d1e7 0x7fd08586246e 0x7fd0858b2c7b 0x7fd0858b335f 0x7fd085955103 0x557023af6424 0x557023af6120 0x557023b6ab80 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023af79da 0x557023b65eae 0x557023b6502f 0x557023af7aba 0x557023b6a2c0 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6566e 0x557023af836c 0x557023b397b9 0x557023b366d4 0x557023af6c29 0x557023b6ae61\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55722d8c2000 @  0x7fd08865d1e7 0x7fd08586246e 0x7fd0858b2c7b 0x7fd0858b335f 0x7fd031262235 0x7fd030be5792 0x7fd030be5d42 0x7fd030b9eaee 0x557023af6317 0x557023af6120 0x557023b6a679 0x557023af79da 0x557023b66108 0x557023b651c0 0x557023a36eb0 0x557023b67633 0x557023b6502f 0x557023af7aba 0x557023b66108 0x557023b6566e 0x557023af7aba 0x557023b66108 0x557023af79da 0x557023b66108 0x557023b6502f 0x557023af8151 0x557023af8571 0x557023b67633 0x557023b6502f 0x557023af7aba 0x557023b65eae\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 1.0\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 2,\n",
            "  \"network_snapshot_ticks\": 2,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/stylegan2-ada/download1\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/stylegan2-ada/download1\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 4,\n",
            "  \"minibatch_gpu\": 4,\n",
            "  \"G_smoothing_kimg\": 1.25,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res512-mirror-stylegan2-noaug.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/Colab Notebooks/results/download1/00003-download1-mirror-auto1-gamma1-resumeffhq512\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/Colab Notebooks/results/download1/00003-download1-mirror-auto1-gamma1-resumeffhq512\n",
            "Training data:     /content/stylegan2-ada/download1\n",
            "Training length:   25000 kimg\n",
            "Resolution:        1024\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55702c294000 @  0x7fd08865f001 0x7fd08586254f 0x7fd0858b2b58 0x7fd0858b6b17 0x7fd085955203 0x557023af6424 0x557023af6120 0x557023b6ab80 0x557023b6566e 0x557023af836c 0x557023b397b9 0x557023b366d4 0x557023af6c29 0x557023b6ae61 0x557023b6502f 0x557023a36e2b 0x557023b67633 0x557023b6502f 0x557023a36e2b 0x557023b67633 0x557023b6566e 0x557023a36e2b 0x557023b67633 0x557023af79da 0x557023b65eae 0x557023b6502f 0x557023b64d43 0x557023c2f302 0x557023c2f67d 0x557023c2f526 0x557023c071d3\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55732d8c2000 @  0x7fd08865d1e7 0x7fd08586246e 0x7fd0858b2c7b 0x7fd0858b335f 0x7fd085955103 0x557023af6424 0x557023af6120 0x557023b6ab80 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023af79da 0x557023b65eae 0x557023b6502f 0x557023af7aba 0x557023b6a2c0 0x557023b6502f 0x557023af7aba 0x557023b66cd4 0x557023b6566e 0x557023af836c 0x557023b397b9 0x557023b366d4 0x557023af6c29 0x557023b6ae61\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55732d8c2000 @  0x7fd08865d1e7 0x7fd08586246e 0x7fd0858b2c7b 0x7fd0858b335f 0x7fd031262235 0x7fd030be5792 0x7fd030be5d42 0x7fd030b9eaee 0x557023af6317 0x557023af6120 0x557023b6a679 0x557023af79da 0x557023b66108 0x557023b651c0 0x557023a36eb0 0x557023b67633 0x557023b6502f 0x557023af7aba 0x557023b66108 0x557023b6566e 0x557023af7aba 0x557023b66108 0x557023af79da 0x557023b66108 0x557023b6502f 0x557023af8151 0x557023af8571 0x557023b67633 0x557023b6502f 0x557023af7aba 0x557023b65eae\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
            "Resuming from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res512-mirror-stylegan2-noaug.pkl\"\n",
            "\n",
            "G                               Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "epochs                          1         ()                   ()              \n",
            "epochs_1                        1         ()                   ()              \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "---                             ---       ---                  ---             \n",
            "Total                           28794126                                       \n",
            "\n",
            "\n",
            "D                     Params    OutputShape          WeightShape     \n",
            "---                   ---       ---                  ---             \n",
            "images_in             -         (?, 3, 1024, 1024)   -               \n",
            "labels_in             -         (?, 0)               -               \n",
            "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
            "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
            "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
            "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
            "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
            "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
            "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
            "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
            "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
            "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
            "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
            "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
            "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
            "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
            "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
            "Output                513       (?, 1)               (512, 1)        \n",
            "---                   ---       ---                  ---             \n",
            "Total                 29012513                                       \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 19s       sec/tick 24.3    sec/kimg 1521.02 maintenance 54.4   gpumem 10.3  augment 0.000\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 645, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 637, in main\n",
            "    run_training(**vars(args))\n",
            "  File \"train.py\", line 522, in run_training\n",
            "    training_loop.training_loop(**training_options)\n",
            "  File \"/content/stylegan2-ada/training/training_loop.py\", line 252, in training_loop\n",
            "    tflib.run([G_train_op, data_fetch_op])\n",
            "  File \"/content/stylegan2-ada/dnnlib/tflib/tfutil.py\", line 33, in run\n",
            "    return tf.get_default_session().run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/Piat0046/stylegan2-ada-.git\n",
        "#!git push -u origin main"
      ],
      "metadata": {
        "id": "tqYXds8F_foA",
        "outputId": "dc0edfb1-4dfe-4fda-f7eb-f2ffbc75a6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/stylegan2-ada/.git/\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@4e2e8063f160.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://github.com/Piat0046/stylegan2-ada-.git\n",
        "!git branch -M main\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "C1PsdMND_nyw",
        "outputId": "0839b1f7-a289-48ed-986a-a1ba4978ef1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: remote origin already exists.\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VnW3A4uo_qTU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}